{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495cd0205ff6ae13",
   "metadata": {},
   "source": [
    "# Using AWS Timestream to query sensor feed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6ef8b600c28934",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This Jupyter notebook guides you through the process of querying sensor data from AWS Timestream. Timestream is AWS's cutting-edge serverless database, purpose-built for efficiently storing time-series data, especially data originating from IoT devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d9781ba10563c0",
   "metadata": {},
   "source": [
    "## Why Timestream\n",
    "\n",
    "Amazon Timestream is a purpose-built, fully managed time-series database service designed to simplify the storage and analysis of time-stamped data at scale. Here are several compelling reasons to choose Amazon Timestream:\n",
    "\n",
    "1. **Time-Series Data Management:**\n",
    "   - *Efficient Storage:* Timestream is optimized for handling time-series data, providing high efficiency in storage and query performance for timestamped information.\n",
    "\n",
    "2. **Serverless and Fully Managed:**\n",
    "   - *Ease of Use:* Timestream is fully managed, eliminating operational overhead. It is serverless, automatically handling tasks such as scaling, patching, and backups.\n",
    "\n",
    "3. **Scalability:**\n",
    "   - *Horizontal Scalability:* Timestream scales horizontally, accommodating a large volume of time-series data as your application grows.\n",
    "\n",
    "4. **Cost-Effective:**\n",
    "   - *Pay-as-You-Go Model:* With a pay-as-you-go pricing model, Timestream is cost-effective, especially for varying workloads.\n",
    "\n",
    "5. **Built-in Analytics:**\n",
    "   - *Query Language:* Timestream provides a SQL-like query language for easy data retrieval, supporting analytical queries for complex analysis on time-series data.\n",
    "\n",
    "6. **Integration with AWS Ecosystem:**\n",
    "   - *Seamless Integration:* Timestream integrates seamlessly with AWS services like Amazon CloudWatch, AWS IoT, and Amazon Kinesis, allowing the ingestion and analysis of data from various sources.\n",
    "\n",
    "7. **Security and Compliance:**\n",
    "   - *AWS Identity and Access Management (IAM):* Timestream integrates with IAM for access control, ensuring secure data handling. It also supports encryption at rest and in transit to meet compliance requirements.\n",
    "\n",
    "8. **Versatility:**\n",
    "   - *Multi-Resolution Storage:* Timestream supports multi-resolution storage, enabling optimization of storage costs based on data access patterns.\n",
    "\n",
    "9. **Time-Windowed Retention Policies:**\n",
    "   - *Data Retention Control:* Timestream allows the definition of retention policies based on time windows, automatically managing the lifecycle of time-series data.\n",
    "\n",
    "10. **Real-time Data Ingestion:**\n",
    "    - *High Throughput:* Timestream supports high-speed, continuous data ingestion, making it suitable for real-time applications and scenarios with rapidly generated data.\n",
    "\n",
    "In summary, Amazon Timestream is an excellent choice for applications requiring efficient storage, analysis, and retrieval of time-series data at scale. It is particularly well-suited for use cases such as IoT, telemetry, monitoring, and analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e92f7318723977",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bcd7e314b64af77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/homebrew/lib/python3.11/site-packages (23.2.1)\n",
      "Collecting pip\n",
      "  Obtaining dependency information for pip from https://files.pythonhosted.org/packages/47/6a/453160888fab7c6a432a6e25f8afe6256d0d9f2cbd25971021da6491d899/pip-23.3.1-py3-none-any.whl.metadata\n",
      "  Downloading pip-23.3.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.2.1\n",
      "    Uninstalling pip-23.2.1:\n",
      "      Successfully uninstalled pip-23.2.1\n",
      "Successfully installed pip-23.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fa639980ceee0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3>=1.28.57\n",
      "  Downloading boto3-1.33.10-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting awscli>=1.29.57\n",
      "  Downloading awscli-1.31.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore>=1.31.57\n",
      "  Downloading botocore-1.33.10-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.9.0,>=0.8.2 (from boto3>=1.28.57)\n",
      "  Downloading s3transfer-0.8.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli>=1.29.57)\n",
      "  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting PyYAML<6.1,>=3.10 (from awscli>=1.29.57)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting colorama<0.4.5,>=0.2.5 (from awscli>=1.29.57)\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli>=1.29.57)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore>=1.31.57)\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<2.1,>=1.25.4 (from botocore>=1.31.57)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore>=1.31.57)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli>=1.29.57)\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading boto3-1.33.10-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading awscli-1.31.10-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.33.10-py3-none-any.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/167.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.8.2-py3-none-any.whl (82 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.0/82.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, six, PyYAML, pyasn1, jmespath, docutils, colorama, rsa, python-dateutil, botocore, s3transfer, boto3, awscli\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.16\n",
      "    Uninstalling urllib3-1.26.16:\n",
      "      Successfully uninstalled urllib3-1.26.16\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.5.0\n",
      "    Uninstalling pyasn1-0.5.0:\n",
      "      Successfully uninstalled pyasn1-0.5.0\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.7.2\n",
      "    Uninstalling rsa-4.7.2:\n",
      "      Successfully uninstalled rsa-4.7.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.2\n",
      "    Uninstalling python-dateutil-2.8.2:\n",
      "      Successfully uninstalled python-dateutil-2.8.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.155\n",
      "    Uninstalling botocore-1.29.155:\n",
      "      Successfully uninstalled botocore-1.29.155\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.1\n",
      "    Uninstalling s3transfer-0.6.1:\n",
      "      Successfully uninstalled s3transfer-0.6.1\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.155\n",
      "    Uninstalling boto3-1.26.155:\n",
      "      Successfully uninstalled boto3-1.26.155\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.25.60\n",
      "    Uninstalling awscli-1.25.60:\n",
      "      Successfully uninstalled awscli-1.25.60\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker 2.165.0 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "aiobotocore 2.4.2 requires botocore<1.27.60,>=1.27.59, but you have botocore 1.33.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 awscli-1.31.10 boto3-1.33.10 botocore-1.33.10 colorama-0.4.4 docutils-0.16 jmespath-1.0.1 pyasn1-0.5.1 python-dateutil-2.8.2 rsa-4.7.2 s3transfer-0.8.2 six-1.16.0 urllib3-2.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367011301978eda0",
   "metadata": {},
   "source": [
    "## Setup AWS Credentials in Jupyter Notebook\n",
    "\n",
    "To set up boto3 credentials in a Jupyter notebook:# Setting up Boto3 Credentials in a Jupyter Notebook\n",
    "\n",
    "To establish Boto3 credentials in a Jupyter notebook, follow these steps:\n",
    "\n",
    "1. **Configure AWS Credentials on the EC2 Instance:**\n",
    "   - Create a credentials file at `~/.aws/credentials`.\n",
    "   - Add the `aws_access_key_id` and `aws_secret_access_key` to this file.\n",
    "\n",
    "     ```plaintext\n",
    "     [default]\n",
    "     aws_access_key_id = YOUR_ACCESS_KEY_ID\n",
    "     aws_secret_access_key = YOUR_SECRET_ACCESS_KEY\n",
    "     ```\n",
    "\n",
    "2. **Alternative Configuration using Environment Variables:**\n",
    "   - Set environment variables `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY` with your credentials.\n",
    "\n",
    "3. **Install Boto3 in the Jupyter Notebook Environment:**\n",
    "   - Execute the following command in a Jupyter notebook cell:\n",
    "\n",
    "     ```bash\n",
    "     !pip install boto3\n",
    "     ```\n",
    "These steps will enable you to set up and use Boto3 credentials within your Jupyter notebook environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "772b3ad000e680bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T02:28:39.407437Z",
     "start_time": "2023-12-08T02:28:39.402399Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# ---- ⚠️ Un-comment and edit the below lines as needed for your AWS setup ⚠️ ----\n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"] = \"<REGION_NAME>\"  # E.g. \"us-east-1\"\n",
    "# os.environ[\"AWS_PROFILE\"] = \"<YOUR_PROFILE>\"\n",
    "\n",
    "session = boto3.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d838b81b8a2bd",
   "metadata": {},
   "source": [
    "## Set environment and region variable to connect to the right database \n",
    "\n",
    "Replace the `ENVIRONMENT` variable with the specific environment used during deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb09ab8c6991440d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T02:28:41.361445Z",
     "start_time": "2023-12-08T02:28:41.343194Z"
    }
   },
   "outputs": [],
   "source": [
    "ENVIRONMENT='dev' # Replace this with the environment that you used when deploying the solution \n",
    "\n",
    "# Insert your database name here\n",
    "DATABASE_NAME=f'afriset-{ENVIRONMENT}'\n",
    "TABLE_NAME=f'afriset-{ENVIRONMENT}-sensor-feeds'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e581355dab5fdc",
   "metadata": {},
   "source": [
    "## Query Helper Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d36b24b9a458cc",
   "metadata": {},
   "source": [
    "Upon completing the file upload through the user interface (UI), the sensor data has been successfully ingested into Timestream. To retrieve this data, we will proceed by creating a Query object capable of executing any written query. The output will be iterated through and displayed on the screen. You can find the relevant code on GitHub at https://github.com/awslabs/amazon-timestream-tools/blob/master/sample_apps/python/QueryExample.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aea2ca2ee291f238",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T02:28:44.924295Z",
     "start_time": "2023-12-08T02:28:44.915760Z"
    }
   },
   "outputs": [],
   "source": [
    "class Query(object):\n",
    "\n",
    "    def __init__(self, client):\n",
    "        self.client = client\n",
    "        self.paginator = client.get_paginator('query')\n",
    "\n",
    "    # See records ingested into this table so far\n",
    "    SELECT_ALL = f\"SELECT * FROM {DATABASE_NAME}.{TABLE_NAME}\"\n",
    "\n",
    "    def run_query(self, query_string):\n",
    "        try:\n",
    "            page_iterator = self.paginator.paginate(QueryString=query_string)\n",
    "            for page in page_iterator:\n",
    "                self._parse_query_result(page)\n",
    "        except Exception as err:\n",
    "            print(\"Exception while running query:\", err)\n",
    "\n",
    "    def _parse_query_result(self, query_result):\n",
    "        column_info = query_result['ColumnInfo']\n",
    "\n",
    "        print(\"Metadata: %s\" % column_info)\n",
    "        print(\"Data: \")\n",
    "        for row in query_result['Rows']:\n",
    "            print(self._parse_row(column_info, row))\n",
    "\n",
    "    def _parse_row(self, column_info, row):\n",
    "        data = row['Data']\n",
    "        row_output = []\n",
    "        for j in range(len(data)):\n",
    "            info = column_info[j]\n",
    "            datum = data[j]\n",
    "            row_output.append(self._parse_datum(info, datum))\n",
    "\n",
    "        return \"{%s}\" % str(row_output)\n",
    "\n",
    "    def _parse_datum(self, info, datum):\n",
    "        if datum.get('NullValue', False):\n",
    "            return \"%s=NULL\" % info['Name'],\n",
    "\n",
    "        column_type = info['Type']\n",
    "\n",
    "        # If the column is of TimeSeries Type\n",
    "        if 'TimeSeriesMeasureValueColumnInfo' in column_type:\n",
    "            return self._parse_time_series(info, datum)\n",
    "\n",
    "        # If the column is of Array Type\n",
    "        elif 'ArrayColumnInfo' in column_type:\n",
    "            array_values = datum['ArrayValue']\n",
    "            return \"%s=%s\" % (info['Name'], self._parse_array(info['Type']['ArrayColumnInfo'], array_values))\n",
    "\n",
    "        # If the column is of Row Type\n",
    "        elif 'RowColumnInfo' in column_type:\n",
    "            row_column_info = info['Type']['RowColumnInfo']\n",
    "            row_values = datum['RowValue']\n",
    "            return self._parse_row(row_column_info, row_values)\n",
    "\n",
    "        # If the column is of Scalar Type\n",
    "        else:\n",
    "            return self._parse_column_name(info) + datum['ScalarValue']\n",
    "\n",
    "    def _parse_time_series(self, info, datum):\n",
    "        time_series_output = []\n",
    "        for data_point in datum['TimeSeriesValue']:\n",
    "            time_series_output.append(\"{time=%s, value=%s}\"\n",
    "                                      % (data_point['Time'],\n",
    "                                         self._parse_datum(info['Type']['TimeSeriesMeasureValueColumnInfo'],\n",
    "                                                           data_point['Value'])))\n",
    "        return \"[%s]\" % str(time_series_output)\n",
    "\n",
    "    def _parse_array(self, array_column_info, array_values):\n",
    "        array_output = []\n",
    "        for datum in array_values:\n",
    "            array_output.append(self._parse_datum(array_column_info, datum))\n",
    "\n",
    "        return \"[%s]\" % str(array_output)\n",
    "\n",
    "    def run_query_with_multiple_pages(self, limit):\n",
    "        query_with_limit = self.SELECT_ALL + \" LIMIT \" + str(limit)\n",
    "        print(\"Starting query with multiple pages : \" + query_with_limit)\n",
    "        self.run_query(query_with_limit)\n",
    "\n",
    "    def cancel_query(self):\n",
    "        print(\"Starting query: \" + self.SELECT_ALL)\n",
    "        result = self.client.query(QueryString=self.SELECT_ALL)\n",
    "        print(\"Cancelling query: \" + self.SELECT_ALL)\n",
    "        try:\n",
    "            self.client.cancel_query(QueryId=result['QueryId'])\n",
    "            print(\"Query has been successfully cancelled\")\n",
    "        except Exception as err:\n",
    "            print(\"Cancelling query failed:\", err)\n",
    "\n",
    "    @staticmethod\n",
    "    def _parse_column_name(info):\n",
    "        if 'Name' in info:\n",
    "            return info['Name'] + \"=\"\n",
    "        else:\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4954a192b9749f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T02:28:46.662658Z",
     "start_time": "2023-12-08T02:28:46.579563Z"
    }
   },
   "outputs": [],
   "source": [
    "query_client = session.client('timestream-query', region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n",
    "\n",
    "query = Query(query_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26c1b04c0c04c4",
   "metadata": {},
   "source": [
    "## Querying the sensor data from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48353f4af803812f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-08T02:28:50.383448Z",
     "start_time": "2023-12-08T02:28:48.566202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: [{'Name': 'measure_name', 'Type': {'ScalarType': 'VARCHAR'}}, {'Name': 'time', 'Type': {'ScalarType': 'TIMESTAMP'}}]\n",
      "Data: \n"
     ]
    }
   ],
   "source": [
    "QUERY_1 = f\"\"\"\n",
    "        SELECT * FROM \"{DATABASE_NAME}\".\"{TABLE_NAME}\" WHERE time between ago(15m) and now() ORDER BY time DESC LIMIT 10 \n",
    "        \"\"\"\n",
    "\n",
    "query_output = query.run_query(QUERY_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddacf9b1003de85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
